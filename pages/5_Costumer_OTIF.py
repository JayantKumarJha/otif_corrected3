# -*- coding: utf-8 -*-
"""5_Costumer_OTIF.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NG8GK18w24yr-jtFuNkrLeS41rl0pmd3
"""

# pages/Customer_OTIF.py
import io
import re
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px

# PDF
try:
    from reportlab.lib.pagesizes import A4
    from reportlab.pdfgen import canvas
    from reportlab.lib.units import mm
    REPORTLAB_OK = True
except Exception:
    REPORTLAB_OK = False

st.set_page_config(page_title="Customer OTIF Analysis", page_icon="🚚", layout="wide")
st.title("🚚 Customer OTIF — Order Level")
st.caption("Upload file with these columns exactly (or close variants): "
           "`COUNTRY, GENERIC NAME, ORDER NO, ORDER QTY., DISPATCH QTY., EXPECTED DISPATCH DATE, ACTUAL DISPATCH DATE`")

# canonical required columns (keep dots)
REQ = [
    "COUNTRY",
    "GENERIC NAME",
    "ORDER NO",
    "ORDER QTY.",
    "DISPATCH QTY.",
    "EXPECTED DISPATCH DATE",
    "ACTUAL DISPATCH DATE",
]

MONTH_ORDER = ["Jan","Feb","Mar","Apr","May","Jun","Jul","Aug","Sep","Oct","Nov","Dec"]

# ---------------- Helpers ----------------
def _normalize_key(s: str) -> str:
    """Normalize a header to a compact key used for fuzzy mapping."""
    if s is None:
        return ""
    k = str(s)
    k = k.replace("\u00A0", " ")  # nbspace
    k = k.strip()
    # remove dots and spaces for mapping
    k = re.sub(r'[\s\.]+', '', k).upper()
    return k

def map_columns_to_canonical(df: pd.DataFrame) -> pd.DataFrame:
    """
    Map input column variants (dots, spaces, case) to canonical REQ names which include dots.
    Example: "order qty" or "ORDER QTY" or "ORDER QTY." -> "ORDER QTY."
    """
    cols = list(df.columns)
    norm_map = { _normalize_key(c): c for c in cols }

    rename = {}
    for canonical in REQ:
        key = re.sub(r'[\s\.]+', '', canonical).upper()
        if key in norm_map:
            rename[norm_map[key]] = canonical

    df = df.rename(columns=rename)
    missing = [c for c in REQ if c not in df.columns]
    if missing:
        raise ValueError(f"Missing required columns after mapping: {missing}. Found cols: {cols}")
    return df

def to_float_series(s: pd.Series) -> pd.Series:
    """Robust float conversion: (1,234) -> -1234, removes commas/spaces."""
    if s.dtype.kind in "biufc":
        return s.astype(float)
    s2 = s.astype(str).str.strip()
    s2 = s2.replace(r'^\s*$', np.nan, regex=True)
    s2 = s2.str.replace(r'^\((.*)\)$', r'-\1', regex=True)    # (1) => -1
    s2 = s2.str.replace(',', '', regex=False).str.replace(' ', '', regex=False)
    return pd.to_numeric(s2, errors='coerce').astype(float)

def to_datetime_utc(series: pd.Series) -> pd.Series:
    # Parse all to timezone-aware UTC to avoid mixing tz-naive and tz-aware
    return pd.to_datetime(series, errors='coerce', dayfirst=True, utc=True)

def load_and_clean(file) -> pd.DataFrame:
    # read
    name = getattr(file, "name", "").lower()
    if name.endswith(".csv"):
        df = pd.read_csv(file)
    else:
        df = pd.read_excel(file)
    # basic header cleanup (keep dots)
    df.columns = [c.replace('\u00A0', ' ').strip() for c in df.columns]
    # map columns robustly to canonical names
    df = map_columns_to_canonical(df)

    # keep only required (in canonical order)
    df = df[REQ].copy()

    # convert numeric and datetime robustly
    df["ORDER QTY."] = to_float_series(df["ORDER QTY."])
    df["DISPATCH QTY."] = to_float_series(df["DISPATCH QTY."])
    df["EXPECTED DISPATCH DATE"] = to_datetime_utc(df["EXPECTED DISPATCH DATE"])
    df["ACTUAL DISPATCH DATE"] = to_datetime_utc(df["ACTUAL DISPATCH DATE"])

    # drop any row missing ANY of the 7 required fields
    df = df.dropna(subset=REQ).copy()

    # strip textual columns
    for c in ["COUNTRY", "GENERIC NAME", "ORDER NO"]:
        df[c] = df[c].astype(str).str.strip()

    # final guard
    df = df[(df["COUNTRY"] != "") & (df["GENERIC NAME"] != "") & (df["ORDER NO"] != "")]
    df = df.reset_index(drop=True)
    return df

def compute_order_level(df: pd.DataFrame):
    # aggregate per line (ORDER NO, GENERIC NAME)
    lines = (df.groupby(["ORDER NO", "GENERIC NAME"], as_index=False)
               .agg({
                    "ORDER QTY.": "sum",
                    "DISPATCH QTY.": "sum",
                    "EXPECTED DISPATCH DATE": "max",
                    "ACTUAL DISPATCH DATE": "max",
                    "COUNTRY": "first"
               }))

    lines["Line_InFull"] = (lines["DISPATCH QTY."] >= 0.95 * lines["ORDER QTY."]).astype(int)
    lines["Line_OnTime"] = (lines["ACTUAL DISPATCH DATE"] <= lines["EXPECTED DISPATCH DATE"]).astype(int)

    # Order-level summary
    orders = (lines.groupby("ORDER NO", as_index=False)
                .agg(
                    Order_InFull=("Line_InFull", "min"),
                    Order_OnTime=("Line_OnTime", "min"),
                    Country=("COUNTRY", "first"),
                    Last_Actual_Dispatch=("ACTUAL DISPATCH DATE", "max")
                ))
    orders["OTIF"] = (orders["Order_InFull"] * orders["Order_OnTime"]).astype(int)

    # bucket date parts from Last_Actual_Dispatch (tz-aware UTC)
    orders["Year"] = orders["Last_Actual_Dispatch"].dt.year
    orders["MonthNum"] = orders["Last_Actual_Dispatch"].dt.month
    orders["Month"] = orders["Last_Actual_Dispatch"].dt.strftime("%b")

    return lines, orders

def generate_failed_orders_pdf_by_country(breaches_df: pd.DataFrame, year: int) -> bytes:
    if not REPORTLAB_OK:
        raise RuntimeError("reportlab not available")
    buf = io.BytesIO()
    width, height = A4
    c = canvas.Canvas(buf, pagesize=A4)
    margin_x = 20 * mm
    y = height - 20 * mm
    lh = 7.5 * mm

    # Title
    c.setFont("Helvetica-Bold", 16)
    c.drawString(margin_x, y, f"ALL OTIF FAILED ORDERS — {year}")
    y -= 12 * mm

    # group countries by count desc
    country_counts = (breaches_df.groupby("Country").size()
                                      .reset_index(name="count")
                                      .sort_values("count", ascending=False))

    idx = 1
    for _, r in country_counts.iterrows():
        country = r["Country"]
        group = breaches_df[breaches_df["Country"] == country].sort_values("Last_Actual_Dispatch", ascending=False)

        if y < 40 * mm:
            c.showPage()
            y = height - 20 * mm
            c.setFont("Helvetica-Bold", 16)
            c.drawString(margin_x, y, f"ALL OTIF FAILED ORDERS — {year} (cont.)")
            y -= 12 * mm

        c.setFont("Helvetica-Bold", 12)
        c.drawString(margin_x, y, f"{idx}. {country}  (Failures: {len(group)})")
        y -= lh

        c.setFont("Helvetica", 10)
        for _, rr in group.iterrows():
            date_str = rr["Last_Actual_Dispatch"].strftime("%d-%m-%Y") if pd.notna(rr["Last_Actual_Dispatch"]) else ""
            order_no = str(rr["ORDER NO"])
            c.drawString(margin_x + 6 * mm, y, f"    {date_str}    {order_no}")
            y -= 6 * mm
            if y < 25 * mm:
                c.showPage()
                y = height - 20 * mm
                c.setFont("Helvetica", 10)
        y -= 4 * mm
        idx += 1

    c.save()
    buf.seek(0)
    return buf.getvalue()

# ---------------- UI ----------------
uploaded = st.file_uploader("📤 Upload Customer OTIF Excel/CSV (single sheet)", type=["xlsx","xls","csv"])
if not uploaded:
    st.info("Expected columns: " + ", ".join(REQ))
    st.stop()

try:
    df = load_and_clean(uploaded)
except Exception as e:
    st.error(f"Processing error: {e}")
    st.stop()

if df.empty:
    st.warning("No rows remain after cleaning/dropping missing values.")
    st.stop()

lines, orders = compute_order_level(df)

# Year selector based on last actual dispatch date
years = sorted(orders["Year"].dropna().astype(int).unique().tolist())
if not years:
    st.error("No valid years found in ACTUAL DISPATCH DATE.")
    st.stop()

selected_year = st.selectbox("📅 Select Year", years, index=len(years)-1)
orders_year = orders[orders["Year"] == selected_year].copy()

# Monthly summary
monthly = (orders_year.groupby(["MonthNum","Month"], as_index=False)
                    .agg(Avg_OTIF=("OTIF","mean"), Total_Orders=("ORDER NO","count"))
                    .sort_values("MonthNum"))

# KPI: only yearly order-level OTIF (plus total orders as you requested earlier)
col1, col2 = st.columns(2)
col1.metric("OTIF (Yearly order-level mean)", f"{orders_year['OTIF'].mean()*100:.1f}%")
col2.metric("Total Orders (Year)", int(orders_year.shape[0]))

# Chart
st.subheader("📊 Monthly OTIF (Selected Year)")
if monthly.empty:
    st.info("No orders for the selected year.")
else:
    present = [m for m in MONTH_ORDER if m in monthly["Month"].tolist()]
    fig = px.bar(monthly, x="Month", y="Avg_OTIF",
                 category_orders={"Month": present},
                 text=monthly["Avg_OTIF"].map(lambda v: f"{v*100:.1f}%"),
                 labels={"Avg_OTIF":"Average OTIF"}, height=420)
    fig.update_traces(textposition="outside")
    fig.update_yaxes(range=[0,1], tickformat=".0%")
    st.plotly_chart(fig, use_container_width=True)

# Monthly table
with st.expander("📄 Monthly Summary Table"):
    tbl = monthly.copy()
    tbl["Avg_OTIF"] = (tbl["Avg_OTIF"]*100).round(1)
    tbl = tbl.rename(columns={"MonthNum":"Month #", "Avg_OTIF":"Avg OTIF (%)"})
    st.dataframe(tbl, use_container_width=True)

# Top countries & failed-orders PDF
st.subheader("🚨 Countries with OTIF Breaches (Selected Year)")
breaches = orders_year[orders_year["OTIF"] == 0].copy()

if breaches.empty:
    st.success("No OTIF breaches in the selected year. 🎉")
else:
    top_countries = (breaches.groupby("Country").size().reset_index(name="OTIF_Breaches")
                                   .sort_values("OTIF_Breaches", ascending=False).head(10))
    st.dataframe(top_countries, use_container_width=True)

    if REPORTLAB_OK:
        try:
            pdf_bytes = generate_failed_orders_pdf_by_country(breaches, selected_year)
            st.download_button("⬇️ Download ALL Failed Orders (PDF)", data=pdf_bytes,
                               file_name=f"Customer_OTIF_failed_orders_{selected_year}.pdf", mime="application/pdf")
        except Exception as e:
            st.error(f"PDF creation error: {e}")
            csv_bytes = breaches[["Country","Last_Actual_Dispatch","ORDER NO"]].sort_values(["Country","Last_Actual_Dispatch"], ascending=[False, False]).to_csv(index=False).encode("utf-8")
            st.download_button("⬇️ Download ALL Failed Orders (CSV fallback)", data=csv_bytes,
                               file_name=f"Customer_OTIF_failed_orders_{selected_year}.csv", mime="text/csv")
    else:
        st.warning("PDF export requires reportlab. Install `pip install reportlab` and restart.")
        csv_bytes = breaches[["Country","Last_Actual_Dispatch","ORDER NO"]].sort_values(["Country","Last_Actual_Dispatch"], ascending=[False, False]).to_csv(index=False).encode("utf-8")
        st.download_button("⬇️ Download ALL Failed Orders (CSV)", data=csv_bytes,
                           file_name=f"Customer_OTIF_failed_orders_{selected_year}.csv", mime="text/csv")

# Downloads
c1, c2 = st.columns([1.5, 1])
with c1:
    st.download_button("⬇️ Download Order-level Data (CSV)", data=orders_year.to_csv(index=False).encode("utf-8"),
                       file_name=f"customer_orders_{selected_year}.csv", mime="text/csv")
with c2:
    st.download_button("⬇️ Download Monthly Summary (CSV)", data=monthly.to_csv(index=False).encode("utf-8"),
                       file_name=f"customer_monthly_otif_{selected_year}.csv", mime="text/csv")

# Debugging panel — show why orders fail (first 10)
with st.expander("🔎 Why orders failed? (sample)"):
    failed_orders = orders_year[orders_year["OTIF"]==0]
    st.write("Total failed orders this year:", int(failed_orders.shape[0]))
    if not failed_orders.empty:
        st.dataframe(failed_orders[["ORDER NO","Country","Last_Actual_Dispatch","Order_InFull","Order_OnTime"]].head(20))
        st.write("Sample failing lines (Line_InFull==0 or Line_OnTime==0):")
        bad_lines = lines.merge(failed_orders[["ORDER NO"]], on="ORDER NO", how="inner")
        bad_lines = bad_lines[(bad_lines["Line_InFull"]==0) | (bad_lines["Line_OnTime"]==0)]
        st.dataframe(bad_lines[["ORDER NO","GENERIC NAME","ORDER QTY.","DISPATCH QTY.","ACTUAL DISPATCH DATE","EXPECTED DISPATCH DATE","Line_InFull","Line_OnTime"]].head(50))